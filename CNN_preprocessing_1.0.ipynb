{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Joe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Joe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "MAX_SONG_LENGTH = 2500\n",
    "SONG_PER_GENRE = 4500\n",
    "DATA_KEYS = ['lyrics','lyrics_labels','unique_words_set','longest_song','genre_index','artist','song_titles']\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH CONSTANTS\n",
    "PICKLE_ROOT = 'data/lyrics/'\n",
    "CHRISTIAN_PATH = 'Christian.pickle'\n",
    "POP_PATH = 'Pop.pickle'\n",
    "ROCK_PATH = 'Rock.pickle'\n",
    "COUNTRY_PATH = 'Country.pickle'\n",
    "RAP_PATH = 'Rap.pickle'\n",
    "\n",
    "OUT_PICKLE = 'CNN_input.pickle' \n",
    "\n",
    "LYRIC_PATHS = [CHRISTIAN_PATH,POP_PATH,ROCK_PATH,COUNTRY_PATH,RAP_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle extraction\n",
    "# pickle looks like -> pickle_lyrics['lyrics'][('song_title', 'artist')]['lyrics']\n",
    "# or - > pickle_lyrics['genre']\n",
    "def load_lyrics():\n",
    "    lyrics_list = []\n",
    "    genres_map = {}\n",
    "    for i,l_path in enumerate(LYRIC_PATHS):\n",
    "        if not os.path.exists(PICKLE_ROOT+l_path):\n",
    "            print('problem occured looking for %s' %(PICKLE_ROOT+l_path))\n",
    "            sys.exit()\n",
    "        print('loading %s%s%s' %(os.getcwd(),PICKLE_ROOT,l_path))\n",
    "        loaded_lyrics = pickle.load(open(PICKLE_ROOT+l_path, \"rb\" ))\n",
    "        genres_map[loaded_lyrics['genre']] = i\n",
    "        lyrics_list.append(loaded_lyrics)\n",
    "        print('number of songs: %d' %(len(loaded_lyrics['lyrics'])))\n",
    "    return lyrics_list, genres_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_and_punct(article):\n",
    "    final_article = []\n",
    "    word_tokens = tokenizer.tokenize(article)\n",
    "    filtered_article = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_article = [x.lower() for x in filtered_article]\n",
    "    filtered_song = ' '.join(filtered_article)\n",
    "    return filtered_song, filtered_article\n",
    "\n",
    "def clean_genre(data):\n",
    "    song_list = []\n",
    "    unique_words_list = []\n",
    "    count = 0\n",
    "    max_length_song = 0\n",
    "    for key, song_info in data['lyrics'].items():\n",
    "        title, artist = key\n",
    "        inner_title = song_info['title']\n",
    "        if count%1000==0:\n",
    "            print('iter - %d: song - %s' %(count, inner_title))\n",
    "        inner_artist = song_info['artist']\n",
    "        song_lyrics = song_info['lyrics']\n",
    "    \n",
    "#       song_lyrics_norm = re.sub(r'[^a-zA-Z0-9-\\']', ' ', song_lyrics).strip()\n",
    "#       song_lyrics_split = song_lyrics_norm.lower().split()\n",
    "        song_lyrics_norm, song_lyrics_split = remove_stop_and_punct(song_lyrics)\n",
    "    \n",
    "        if len(song_lyrics_split) <= MAX_SONG_LENGTH:\n",
    "            if len(song_lyrics_split) > max_length_song:\n",
    "                max_length_song = len(song_lyrics_split)\n",
    "            song_list.append(song_lyrics_norm)\n",
    "            unique_words_list = list(set(unique_words_list + song_lyrics_split))\n",
    "        count+=1\n",
    "        \n",
    "        if count >= SONG_PER_GENRE:\n",
    "            print('hit max songs: %d' %(SONG_PER_GENRE))\n",
    "            print('songs left out: %d' %(len(data['lyrics'])-SONG_PER_GENRE))\n",
    "            print('longest song length: %d' %(max_length_song))\n",
    "            return song_list, unique_words_list, max_length_song\n",
    "       \n",
    "    return song_list, unique_words_list, max_length_song\n",
    "\n",
    "def clean_data(p_lyrics,genre_index):\n",
    "    lyrics = []\n",
    "    lyrics_labels = []\n",
    "    unique_words_set = []\n",
    "    longest_song = 0\n",
    "    for data in p_lyrics:\n",
    "        genre = data['genre']\n",
    "        print('cleaning: %s' %(genre))\n",
    "        song_list, unique_words, g_longest_song = clean_genre(data)\n",
    "        unique_words_set = list(set(unique_words_set+unique_words))\n",
    "        song_labels = [genre_index[genre]]*len(song_list)\n",
    "        if longest_song < g_longest_song:\n",
    "            longest_song = g_longest_song\n",
    "        lyrics = lyrics + song_list\n",
    "        lyrics_labels = lyrics_labels + song_labels\n",
    "    return [lyrics, lyrics_labels, unique_words_set, longest_song, genre_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_data(filepath,filename, list_data):\n",
    "    data = {}\n",
    "    print('keys match data: %s' %(len(list_data)==len(DATA_KEYS)))\n",
    "    for key,val in zip(DATA_KEYS,list_data):\n",
    "        data[key] = val\n",
    "#     data['lyrics'] = lyrics\n",
    "#     data['lyrics_labels'] = labels\n",
    "#     data['unique_words_set'] = unique_words\n",
    "#     data['genre_index'] = genres\n",
    "    pickle.dump( data, open(filepath+filename, \"wb\" ) )\n",
    "    print('saved data to: %s%s' %(filepath,filename))\n",
    "    \n",
    "def verify_data(filepath,filename, list_data):\n",
    "    loaded_data = pickle.load( open(filepath + filename , \"rb\" ) )\n",
    "    print('keys match loaded data: %s' %(len(loaded_data)==len(list_data)))\n",
    "    for key,val in zip(DATA_KEYS,list_data):\n",
    "        try:\n",
    "            data_check = (len(loaded_data[key])==len(val))\n",
    "        except:\n",
    "            data_check = (loaded_data[key]==val)\n",
    "        if data_check == False:\n",
    "            print('ERROR: Data saved does not match at:')\n",
    "            print(key)\n",
    "            print('please rerun and check paths')\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickles\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Christian.pickle\n",
      "number of songs: 6895\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Pop.pickle\n",
      "number of songs: 5818\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Rock.pickle\n",
      "number of songs: 5596\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Country.pickle\n",
      "number of songs: 5368\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Rap.pickle\n",
      "number of songs: 4747\n",
      "genres dict\n",
      "{'Christian': 0, 'Pop': 1, 'Rock': 2, 'Country': 3, 'Rap': 4}\n",
      "finished loading pickles\n",
      "cleaning data\n",
      "cleaning: Christian\n",
      "iter - 0: song - Never Gonna Let Me Go\n",
      "iter - 1000: song - By His Wounds\n",
      "iter - 2000: song - Living For You\n",
      "iter - 3000: song - Whole World\n",
      "iter - 4000: song - I Manipulate\n",
      "hit max songs: 4500\n",
      "songs left out: 2395\n",
      "longest song length: 612\n",
      "cleaning: Pop\n",
      "iter - 0: song - Emotional\n",
      "iter - 1000: song - Day Is Done\n",
      "iter - 2000: song - Roll Witchu\n",
      "iter - 3000: song - Broken Glass\n",
      "iter - 4000: song - Bitchin' Summer\n",
      "hit max songs: 4500\n",
      "songs left out: 1318\n",
      "longest song length: 734\n",
      "cleaning: Rock\n",
      "iter - 0: song - Pleasure\n",
      "iter - 1000: song - Interesting Drug\n",
      "iter - 2000: song - Vilify\n",
      "iter - 3000: song - Almost (Sweet Music)\n",
      "iter - 4000: song - Unbelievers\n",
      "hit max songs: 4500\n",
      "songs left out: 1096\n",
      "longest song length: 617\n",
      "cleaning: Country\n",
      "iter - 0: song - Here Comes My Baby\n",
      "iter - 1000: song - Passionate Kisses\n",
      "iter - 2000: song - My Favorite Memory\n",
      "iter - 3000: song - Tattoos On This Town\n",
      "iter - 4000: song - My Old Man\n",
      "hit max songs: 4500\n",
      "songs left out: 868\n",
      "longest song length: 552\n",
      "cleaning: Rap\n",
      "iter - 0: song - Can't Tell\n",
      "iter - 1000: song - Dollar Sign\n",
      "iter - 2000: song - U Don't Know Me\n",
      "iter - 3000: song - Barbie Dreams\n",
      "iter - 4000: song - Haters Listen Up!\n",
      "hit max songs: 4500\n",
      "songs left out: 247\n",
      "longest song length: 1318\n",
      "\n",
      "\n",
      "number of songs: 22500\n",
      "number of lyrics: 22500\n",
      "number of unique words: 54404\n",
      "number of genres: 5\n",
      "longest song : 1318\n",
      "finished cleaning data\n",
      "keys match data: True\n",
      "saved data to: data/lyrics/CNN_input.pickle\n",
      "verifying data stored\n",
      "keys match loaded data: True\n",
      "All data verified : True\n"
     ]
    }
   ],
   "source": [
    "def main(argv):\n",
    "    pickle_lyrics = []\n",
    "    genre_index = {}\n",
    "    print('loading pickles')\n",
    "    pickle_lyrics, genre_index = load_lyrics()\n",
    "    print('genres dict')\n",
    "    print(genre_index)\n",
    "    print('finished loading pickles')\n",
    "    \n",
    "    print('cleaning data')\n",
    "    new_data = clean_data(pickle_lyrics,genre_index)\n",
    "    lyrics = new_data[0]\n",
    "    lyrics_labels = new_data[1]\n",
    "    unique_words_set = new_data[2]\n",
    "    longest_song = new_data[3]\n",
    "    print('\\n')\n",
    "    print('number of songs: %d' %(len(lyrics)))\n",
    "    print('number of lyrics: %d' %(len(lyrics_labels)))\n",
    "    print('number of unique words: %d' %(len(unique_words_set)))\n",
    "    print('number of genres: %d' %(len(genre_index)))\n",
    "    print('longest song : %d' %(longest_song))\n",
    "    print('finished cleaning data')\n",
    "    \n",
    "    if SAVE:\n",
    "        \n",
    "        save_prepared_data(PICKLE_ROOT,OUT_PICKLE,new_data)\n",
    "        print('verifying data stored')\n",
    "        verified = verify_data(PICKLE_ROOT,OUT_PICKLE,new_data)\n",
    "        print('All data verified : %s' %(verified))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
