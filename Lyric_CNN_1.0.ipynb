{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "VALIDATION_SPLIT = 0.2\n",
    "learning_rate = .0000001\n",
    "max_grad_norm = 1.\n",
    "dropout = 0.5\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH CONSTANTS\n",
    "PICKLE_ROOT = 'data/lyrics/'\n",
    "CHRISTIAN_PATH = 'Christian.pickle'\n",
    "POP_PATH = 'Pop.pickle'\n",
    "ROCK_PATH = 'Rock.pickle'\n",
    "COUNTRY_PATH = 'Country.pickle'\n",
    "RAP_PATH = 'Rap.pickle'\n",
    "\n",
    "LYRIC_PATHS = [CHRISTIAN_PATH,POP_PATH,ROCK_PATH,COUNTRY_PATH,RAP_PATH]\n",
    "\n",
    "EMBEDDING_PATH = 'data/glove_embeddings/'\n",
    "EMBEDDING_FILE = 'glove.6B.'+str(EMBEDDING_DIM)+'d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "# Elmo could improve the word embeddings - need more research\n",
    "# elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "if not os.path.exists(EMBEDDING_PATH+EMBEDDING_FILE):\n",
    "    print('Embeddings not found, downloading now')\n",
    "    ! cd EMBEDDING_PATH\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "    ! unzip glove.6B.zip\n",
    "    ! cd ../..c\n",
    "\n",
    "glove_embeddings = {}\n",
    "with open(EMBEDDING_PATH+EMBEDDING_FILE) as emb_f:\n",
    "    for line in emb_f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Christian.pickle\n",
      "10186\n",
      "('Never Gonna Let Me Go', 'Tauren Wells')\n",
      "334\n",
      "0\n",
      "('Forward Motion', 'Thousand Foot Krutch')\n",
      "379\n",
      "0\n",
      "('Love Brought Me Back', 'Helen Baylor')\n",
      "491\n",
      "0\n",
      "('Moments Like This', 'B.Reith')\n",
      "502\n",
      "0\n",
      "('Independence Day', 'Whiteheart')\n",
      "5957\n",
      "0\n",
      "('Pray For My Enemies', 'Bruce Carroll')\n",
      "10828\n",
      "0\n",
      "('Great Things', 'Dallas Holm')\n",
      "35571\n",
      "0\n",
      "('Open Heaven Lord', 'Steve Camp')\n",
      "37985\n",
      "0\n",
      "('One Time In Each Forever', 'Wayne Watson')\n",
      "50503\n",
      "0\n",
      "('Wisdom Way', 'Aaron Jeoffrey')\n",
      "57599\n",
      "0\n",
      "(\"Big Man's Hat\", 'Charlie Peacock')\n",
      "84663\n",
      "0\n",
      "('Answer To Prayer', 'Bruce Carroll')\n",
      "108479\n",
      "0\n",
      "('Carried Away (Safe On The Wings Of The Lord)', 'Whiteheart')\n",
      "109095\n",
      "0\n",
      "('God Has Another Plan', 'Babbie Mason')\n",
      "121583\n",
      "0\n",
      "('Star Of The Ages', 'Babbie Mason')\n",
      "148554\n",
      "0\n",
      "('A Consistent Ethic Of Human Life', 'Derek Webb')\n",
      "154678\n",
      "0\n",
      "/Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Pop.pickle\n",
      "8618\n",
      "/Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Rock.pickle\n",
      "8054\n",
      "/Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Country.pickle\n",
      "7516\n",
      "/Users/Joe/Applications/OneDrive/School/Spring 2019 - senior/NLP/project/tag_my_lyricsdata/lyrics/Rap.pickle\n",
      "8247\n",
      "5\n",
      "{'Christian': 0, 'Pop': 1, 'Rock': 2, 'Country': 3, 'Rap': 4}\n"
     ]
    }
   ],
   "source": [
    "# Pickle extraction\n",
    "# pickle looks like -> pickle_lyrics['lyrics'][('song_title', 'artist')]['lyrics']\n",
    "# or - > pickle_lyrics['genre']\n",
    "pickle_lyrics = []\n",
    "genre_index = {}\n",
    "max_length = 0\n",
    "for i,l_path in enumerate(LYRIC_PATHS):\n",
    "    if not os.path.exists(PICKLE_ROOT+l_path):\n",
    "        print('problem occured looking for %s' %(PICKLE_ROOT+l_path))\n",
    "        sys.exit()\n",
    "    print(os.getcwd()+PICKLE_ROOT+l_path)\n",
    "    loaded_lyrics = pickle.load(open(PICKLE_ROOT+l_path, \"rb\" ))\n",
    "    genre_index[loaded_lyrics['genre']] = i\n",
    "    pickle_lyrics.append(loaded_lyrics)\n",
    "    print(len(loaded_lyrics['lyrics']))\n",
    "    for key, song_info in loaded_lyrics['lyrics'].items():\n",
    "        if len(song_info['lyrics'].split()) > max_length:\n",
    "            max_length = len(song_info['lyrics'].split())\n",
    "            print(key)\n",
    "            print(max_length)\n",
    "            print(i)\n",
    "print(len(pickle_lyrics))\n",
    "print(genre_index)\n",
    "# print(max_length)\n",
    "# print(pickle_lyrics[0]['lyrics']['Cabin Essence: Chorus', 'The Beach Boys']['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christian\n",
      "('Price Tag', \"Da' T.R.U.T.H.\")\n",
      "1104\n",
      "10186  :  6895\n",
      "Pop\n",
      "('Tropico', 'Lana Del Rey')\n",
      "1129\n",
      "8618  :  5818\n",
      "Rock\n",
      "('The Real Slim Shady', 'Eminem')\n",
      "1013\n",
      "8054  :  5596\n",
      "Country\n",
      "('The Haircut Song', 'Ray Stevens')\n",
      "877\n",
      "7516  :  5368\n",
      "Rap\n",
      "('Mortal Man', 'Kendrick Lamar')\n",
      "2234\n",
      "8247  :  4747\n",
      "51519\n"
     ]
    }
   ],
   "source": [
    "def check_validity(data):\n",
    "    valid_count = 0\n",
    "    max_len_key = ''\n",
    "    max_len = 0\n",
    "    total_words = []\n",
    "    for key, song_info in data['lyrics'].items():\n",
    "        title, artist = key\n",
    "        inner_title = song_info['title']\n",
    "        inner_artist = song_info['artist']\n",
    "        song_lyrics = song_info['lyrics']\n",
    "        song_lyrics_norm = re.sub(r'[^a-zA-Z0-9-\\']', ' ', song_lyrics).strip().lower()\n",
    "        song_lyrics_split = song_lyrics_norm.split()         \n",
    "        if title == inner_title and artist == inner_artist and len(song_lyrics_split) <= 2500:\n",
    "            if len(song_lyrics_split) > max_len:\n",
    "                max_len = len(song_lyrics_split)\n",
    "                max_len_key = key\n",
    "            valid_count+=1\n",
    "            total_words = list(set(total_words+song_lyrics_split))\n",
    "    print(max_len_key)\n",
    "    print(max_len)\n",
    "    return valid_count, total_words\n",
    "\n",
    "for data in pickle_lyrics:\n",
    "    print(data['genre'])\n",
    "    total_songs = len(data['lyrics'])\n",
    "    total_words_set = []\n",
    "    valid, total_words = check_validity(data)\n",
    "    total_words_set  = list(set(total_words_set+total_words))\n",
    "    print(total_songs, ' : ', valid)\n",
    "print(len(total_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All my life, I've had questions\n",
      "Who, what, when, where, why?\n",
      "Wasting time looking for answers\n",
      "Going out my mind\n",
      "I wanted to see behind the scenes\n",
      "But now I'm letting go\n",
      "'Cause the safest place that I can be\n",
      "Is in Your great unknown\n",
      "\n",
      "\n",
      "I'm ready to chase impossible\n",
      "Walking away from what I know\n",
      "(In everything I know)\n",
      "You're never gonna let me go\n",
      "I'm tearing apart my master plan\n",
      "Trading it for my master's hand\n",
      "(In everything I know)\n",
      "You're never gonna let me go\n",
      "\n",
      "\n",
      "Let me go, You're never gonna let me go\n",
      "Let me go, You're never gonna let me go\n",
      "\n",
      "\n",
      "Take me out into Your waters\n",
      "Let's get lost at sea (lost at sea)\n",
      "I feel the voice of You my Father\n",
      "Calm the storm in me\n",
      "I'm not looking for the distant shore\n",
      "Or how the story ends\n",
      "My life is Yours, I'm living for\n",
      "The moment that I'm in\n",
      "\n",
      "\n",
      "I'm ready to chase impossible\n",
      "Walking away from what I know\n",
      "(In everything I know)\n",
      "You're never gonna let me go\n",
      "I'm tearing apart my master plan\n",
      "Trading it for my master's hand\n",
      "(In everything I know )\n",
      "You're never gonna let me go\n",
      "\n",
      "\n",
      "Oh, You're holding on to me\n",
      "My life will always be in Your hands\n",
      "Oh, You're holding on to me\n",
      "My life will always be in Your hands\n",
      "No, You won't let me go\n",
      "Oooh\n",
      "\n",
      "\n",
      "I'm ready to chase impossible\n",
      "Walking away from what I know\n",
      "(In everything I know)\n",
      "You're never gonna let me go\n",
      "I'm tearing apart my master plan\n",
      "Trading it for my master's hand\n",
      "(In everything I know )\n",
      "You're never gonna let me go\n",
      "\n",
      "\n",
      "Let me go, You're never gonna let me go\n",
      "Let me go, You're never gonna let me go\n",
      "Let me go, You're never gonna let me go\n",
      "Let me go, You're never gonna let me go\n",
      "Let me go, You're never gonna let me go\n",
      "Let me go, You're never gonna let me go\n",
      "\n",
      "All my life  I've had questions Who  what  when  where  why  Wasting time looking for answers Going out my mind I wanted to see behind the scenes But now I'm letting go 'Cause the safest place that I can be Is in Your great unknown   I'm ready to chase impossible Walking away from what I know  In everything I know  You're never gonna let me go I'm tearing apart my master plan Trading it for my master's hand  In everything I know  You're never gonna let me go   Let me go  You're never gonna let me go Let me go  You're never gonna let me go   Take me out into Your waters Let's get lost at sea  lost at sea  I feel the voice of You my Father Calm the storm in me I'm not looking for the distant shore Or how the story ends My life is Yours  I'm living for The moment that I'm in   I'm ready to chase impossible Walking away from what I know  In everything I know  You're never gonna let me go I'm tearing apart my master plan Trading it for my master's hand  In everything I know   You're never gonna let me go   Oh  You're holding on to me My life will always be in Your hands Oh  You're holding on to me My life will always be in Your hands No  You won't let me go Oooh   I'm ready to chase impossible Walking away from what I know  In everything I know  You're never gonna let me go I'm tearing apart my master plan Trading it for my master's hand  In everything I know   You're never gonna let me go   Let me go  You're never gonna let me go Let me go  You're never gonna let me go Let me go  You're never gonna let me go Let me go  You're never gonna let me go Let me go  You're never gonna let me go Let me go  You're never gonna let me go\n",
      "\n",
      "['All', 'my', 'life', \"I've\", 'had', 'questions', 'Who', 'what', 'when', 'where', 'why', 'Wasting', 'time', 'looking', 'for', 'answers', 'Going', 'out', 'my', 'mind', 'I', 'wanted', 'to', 'see', 'behind', 'the', 'scenes', 'But', 'now', \"I'm\", 'letting', 'go', \"'Cause\", 'the', 'safest', 'place', 'that', 'I', 'can', 'be', 'Is', 'in', 'Your', 'great', 'unknown', \"I'm\", 'ready', 'to', 'chase', 'impossible', 'Walking', 'away', 'from', 'what', 'I', 'know', 'In', 'everything', 'I', 'know', \"You're\", 'never', 'gonna', 'let', 'me', 'go', \"I'm\", 'tearing', 'apart', 'my', 'master', 'plan', 'Trading', 'it', 'for', 'my', \"master's\", 'hand', 'In', 'everything', 'I', 'know', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Take', 'me', 'out', 'into', 'Your', 'waters', \"Let's\", 'get', 'lost', 'at', 'sea', 'lost', 'at', 'sea', 'I', 'feel', 'the', 'voice', 'of', 'You', 'my', 'Father', 'Calm', 'the', 'storm', 'in', 'me', \"I'm\", 'not', 'looking', 'for', 'the', 'distant', 'shore', 'Or', 'how', 'the', 'story', 'ends', 'My', 'life', 'is', 'Yours', \"I'm\", 'living', 'for', 'The', 'moment', 'that', \"I'm\", 'in', \"I'm\", 'ready', 'to', 'chase', 'impossible', 'Walking', 'away', 'from', 'what', 'I', 'know', 'In', 'everything', 'I', 'know', \"You're\", 'never', 'gonna', 'let', 'me', 'go', \"I'm\", 'tearing', 'apart', 'my', 'master', 'plan', 'Trading', 'it', 'for', 'my', \"master's\", 'hand', 'In', 'everything', 'I', 'know', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Oh', \"You're\", 'holding', 'on', 'to', 'me', 'My', 'life', 'will', 'always', 'be', 'in', 'Your', 'hands', 'Oh', \"You're\", 'holding', 'on', 'to', 'me', 'My', 'life', 'will', 'always', 'be', 'in', 'Your', 'hands', 'No', 'You', \"won't\", 'let', 'me', 'go', 'Oooh', \"I'm\", 'ready', 'to', 'chase', 'impossible', 'Walking', 'away', 'from', 'what', 'I', 'know', 'In', 'everything', 'I', 'know', \"You're\", 'never', 'gonna', 'let', 'me', 'go', \"I'm\", 'tearing', 'apart', 'my', 'master', 'plan', 'Trading', 'it', 'for', 'my', \"master's\", 'hand', 'In', 'everything', 'I', 'know', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go', 'Let', 'me', 'go', \"You're\", 'never', 'gonna', 'let', 'me', 'go']\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def strip_word(words): \n",
    "    word_list = []\n",
    "    word_norm = re.sub(r'[^\\w]', '', words).strip()\n",
    "    if word_norm.isdigit():\n",
    "        word_list.append(word_norm)\n",
    "    else:\n",
    "        word_norm = re.sub(r'[^a-zA-Z]', ' ', words).strip()\n",
    "        word_list = word_norm.split(' ')\n",
    "    return word_list\n",
    "\n",
    "def clean_data(data):\n",
    "    song_list = []\n",
    "    for key, song_info in data['lyrics'].items():\n",
    "        title, artist = key\n",
    "        inner_title = song_info['title']\n",
    "        inner_artist = song_info['artist']\n",
    "        song_lyrics = song_info['lyrics']\n",
    "        song_lyrics_norm = re.sub(r'[^a-zA-Z0-9-\\']', ' ', song_lyrics).strip()\n",
    "        song_lyrics_split = song_lyrics_norm.split()         \n",
    "        if title == inner_title and artist == inner_artist and len(song_lyrics_split) <= 2500:       \n",
    "            song_list.append(song_lyrics_norm)\n",
    "            \n",
    "    return song_list\n",
    "            \n",
    "# initial data pre-processing\n",
    "# assuming a list of tokenized data \n",
    "# vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_document_len)\n",
    "lyrics = []\n",
    "lyrics_labels = []\n",
    "for data in pickle_lyrics:\n",
    "    genre = data['genre']\n",
    "    for key, song_info in data['lyrics'].items():\n",
    "        song_lyrics = song_info['lyrics']\n",
    "        song_lyrics_norm = re.sub(r'[^a-zA-Z0-9-\\']', ' ', song_lyrics).strip()\n",
    "        song_lyrics_split = song_lyrics_norm.split() \n",
    "        print(song_lyrics)\n",
    "        print()\n",
    "        print(song_lyrics_norm)\n",
    "        print()\n",
    "        print(song_lyrics_split)\n",
    "        sys.exit()\n",
    "        lyrics_labels.append(genre_index[genre])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
