{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Joe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Joe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "MAX_SONG_LENGTH = 2500\n",
    "SONG_PER_GENRE = 4500\n",
    "THRESH = 2000\n",
    "REMOVE_COMMON_WORDS = True\n",
    "DATA_KEYS = ['lyrics','lyrics_labels','unique_words_set','longest_song','genre_index','artist','song_titles']\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH CONSTANTS\n",
    "PICKLE_ROOT = '../data/lyrics/original_pickles/'\n",
    "PICKLE_OUT_PATH = '../data/lyrics/'\n",
    "CHRISTIAN_PATH = 'Christian.pickle'\n",
    "POP_PATH = 'Pop.pickle'\n",
    "ROCK_PATH = 'Rock.pickle'\n",
    "COUNTRY_PATH = 'Country.pickle'\n",
    "RAP_PATH = 'Rap.pickle'\n",
    "OUT_PICKLE = 'CNN_input.pickle' \n",
    "\n",
    "LYRIC_PATHS = [CHRISTIAN_PATH,POP_PATH,ROCK_PATH,COUNTRY_PATH,RAP_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle extraction\n",
    "# pickle looks like -> pickle_lyrics['lyrics'][('song_title', 'artist')]['lyrics']\n",
    "# or - > pickle_lyrics['genre']\n",
    "def load_lyrics():\n",
    "    lyrics_list = []\n",
    "    genres_map = {}\n",
    "    for i,l_path in enumerate(LYRIC_PATHS):\n",
    "        if not os.path.exists(PICKLE_ROOT+l_path):\n",
    "            print('problem occured looking for %s' %(PICKLE_ROOT+l_path))\n",
    "            sys.exit()\n",
    "        print('loading %s%s%s' %(os.getcwd(),PICKLE_ROOT,l_path))\n",
    "        loaded_lyrics = pickle.load(open(PICKLE_ROOT+l_path, \"rb\" ))\n",
    "        genres_map[loaded_lyrics['genre']] = i\n",
    "        lyrics_list.append(loaded_lyrics)\n",
    "        print('number of songs: %d' %(len(loaded_lyrics['lyrics'])))\n",
    "    return lyrics_list, genres_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_and_punct(article):\n",
    "    final_article = []\n",
    "    word_tokens = tokenizer.tokenize(article)\n",
    "    filtered_article = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_article = [x.lower() for x in filtered_article]\n",
    "    filtered_song = ' '.join(filtered_article)\n",
    "    return filtered_song, filtered_article\n",
    "\n",
    "def remove_similar_word(word_list,word_count):\n",
    "    new_word_list = []\n",
    "    for word in word_list:\n",
    "        keep = False\n",
    "        for key,count in word_count[word].items():\n",
    "            if count < THRESH:\n",
    "                keep = True\n",
    "        if keep:\n",
    "            new_word_list.append(word)\n",
    "    return new_word_list\n",
    "            \n",
    "        \n",
    "def clean_genre(data,word_count):\n",
    "    song_list = []\n",
    "    unique_words_list = []\n",
    "    count = 0\n",
    "    max_length_song = 0\n",
    "    for key, song_info in data['lyrics'].items():\n",
    "        title, artist = key\n",
    "        inner_title = song_info['title']\n",
    "        if count%1000==0:\n",
    "            print('iter - %d: song - %s' %(count, inner_title))\n",
    "            \n",
    "        inner_artist = song_info['artist']\n",
    "        song_lyrics = song_info['lyrics']\n",
    "        song_lyrics_norm, song_lyrics_split = remove_stop_and_punct(song_lyrics)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if title == inner_title and artist == inner_artist:\n",
    "            if len(song_lyrics_split) <= MAX_SONG_LENGTH:\n",
    "                if REMOVE_COMMON_WORDS:\n",
    "                    song_lyrics_split = remove_similar_word(song_lyrics_split,word_count)\n",
    "                    song_lyrics_norm = ' '.join(song_lyrics_split)\n",
    "                if len(song_lyrics_split) > max_length_song:\n",
    "                    max_length_song = len(song_lyrics_split)\n",
    "                song_list.append(song_lyrics_norm)\n",
    "                unique_words_list = list(set(unique_words_list + song_lyrics_split))\n",
    "            count+=1\n",
    "        \n",
    "        if count >= SONG_PER_GENRE:\n",
    "            print('hit max songs: %d' %(SONG_PER_GENRE))\n",
    "            print('songs left out: %d' %(len(data['lyrics'])-SONG_PER_GENRE))\n",
    "            print('longest song length: %d' %(max_length_song))\n",
    "            return song_list, unique_words_list, max_length_song\n",
    "       \n",
    "    return song_list, unique_words_list, max_length_song\n",
    "\n",
    "def clean_data(p_lyrics,genre_index,word_count):\n",
    "    lyrics = []\n",
    "    lyrics_labels = []\n",
    "    unique_words_set = []\n",
    "    longest_song = 0\n",
    "    for data in p_lyrics:\n",
    "        genre = data['genre']\n",
    "        print('cleaning: %s' %(genre))\n",
    "        song_list, unique_words, g_longest_song = clean_genre(data,word_count)\n",
    "        unique_words_set = list(set(unique_words_set+unique_words))\n",
    "        song_labels = [genre_index[genre]]*len(song_list)\n",
    "        if longest_song < g_longest_song:\n",
    "            longest_song = g_longest_song\n",
    "        lyrics = lyrics + song_list\n",
    "        lyrics_labels = lyrics_labels + song_labels\n",
    "    return [lyrics, lyrics_labels, unique_words_set, longest_song, genre_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_data(filepath,filename, list_data):\n",
    "    data = {}\n",
    "    print('keys match data: %s' %(len(list_data)==len(DATA_KEYS)))\n",
    "    for key,val in zip(DATA_KEYS,list_data):\n",
    "        data[key] = val\n",
    "    pickle.dump( data, open(filepath+filename, \"wb\" ) )\n",
    "    print('saved data to: %s%s' %(filepath,filename))\n",
    "    \n",
    "def verify_data(filepath,filename, list_data):\n",
    "    loaded_data = pickle.load( open(filepath + filename , \"rb\" ) )\n",
    "    print('keys match loaded data: %s' %(len(loaded_data)==len(list_data)))\n",
    "    for key,val in zip(DATA_KEYS,list_data):\n",
    "        try:\n",
    "            data_check = (len(loaded_data[key])==len(val))\n",
    "        except:\n",
    "            data_check = (loaded_data[key]==val)\n",
    "        if data_check == False:\n",
    "            print('ERROR: Data saved does not match at:')\n",
    "            print(key)\n",
    "            print('please rerun and check paths')\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_per_genre(p_lyrics):\n",
    "    word_count = {}\n",
    "    for data in p_lyrics:\n",
    "        genre = data['genre']\n",
    "        for key, song_info in data['lyrics'].items():\n",
    "            song_lyrics = song_info['lyrics']\n",
    "            song_lyrics_norm, song_lyrics_split = remove_stop_and_punct(song_lyrics)\n",
    "            song_word_count = Counter(song_lyrics_split)\n",
    "            for word, count in song_word_count.items():\n",
    "                if word in word_count:\n",
    "                    if genre in word_count[word]:\n",
    "                        word_count[word][genre]+=count\n",
    "                    else:\n",
    "                        word_count[word][genre] = count\n",
    "                else:\n",
    "                    word_count[word] = {}\n",
    "                    word_count[word][genre] = count\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_occurences(word_count):\n",
    "    common_words = []\n",
    "    for word,genre in word_count.items():\n",
    "        keep = False\n",
    "        for genre_key, count in word_count[word].items():\n",
    "            if count < THRESH:\n",
    "                keep = True\n",
    "        if not keep:\n",
    "            common_words.append(word)\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickles\n",
      "problem occured looking for ../data/lyrics/original_pickle/Christian.pickle\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joe/anaconda3/envs/hw/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(argv):\n",
    "    pickle_lyrics = []\n",
    "    genre_index = {}\n",
    "    word_count = {}\n",
    "    print('loading pickles')\n",
    "    pickle_lyrics, genre_index = load_lyrics()\n",
    "    print('genres dict')\n",
    "    print(genre_index)\n",
    "    print('finished loading pickles')\n",
    "    \n",
    "    print('counting words')\n",
    "    word_count = count_words_per_genre(pickle_lyrics)\n",
    "    print('finished counting')\n",
    "    print(find_most_occurences(word_count))\n",
    "    \n",
    "    print('cleaning data')\n",
    "    new_data = clean_data(pickle_lyrics,genre_index,word_count)\n",
    "    lyrics = new_data[0]\n",
    "    lyrics_labels = new_data[1]\n",
    "    unique_words_set = new_data[2]\n",
    "    longest_song = new_data[3]\n",
    "    print('\\n')\n",
    "    print('number of songs: %d' %(len(lyrics)))\n",
    "    print('number of lyrics: %d' %(len(lyrics_labels)))\n",
    "    print('number of unique words: %d' %(len(unique_words_set)))\n",
    "    print('number of genres: %d' %(len(genre_index)))\n",
    "    print('longest song : %d' %(longest_song))\n",
    "    print('finished cleaning data')\n",
    "    \n",
    "    if SAVE:\n",
    "        \n",
    "        save_prepared_data(PICKLE_OUT_PATH,OUT_PICKLE,new_data)\n",
    "        print('verifying data stored')\n",
    "        verified = verify_data(PICKLE_OUT_PATH,OUT_PICKLE,new_data)\n",
    "        print('All data verified : %s' %(verified))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
