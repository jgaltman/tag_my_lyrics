{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Joe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Joe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "MAX_SONG_LENGTH = 2500\n",
    "SONG_PER_GENRE = 4500\n",
    "DATA_KEYS = ['lyrics','lyrics_labels','unique_words_set','longest_song','genre_index','artist','song_titles']\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH CONSTANTS\n",
    "PICKLE_ROOT = '../data/lyrics/'\n",
    "CHRISTIAN_PATH = 'Christian.pickle'\n",
    "POP_PATH = 'Pop.pickle'\n",
    "ROCK_PATH = 'Rock.pickle'\n",
    "COUNTRY_PATH = 'Country.pickle'\n",
    "RAP_PATH = 'Rap.pickle'\n",
    "\n",
    "OUT_PICKLE = 'CNN_input.pickle' \n",
    "\n",
    "LYRIC_PATHS = [CHRISTIAN_PATH,POP_PATH,ROCK_PATH,COUNTRY_PATH,RAP_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle extraction\n",
    "# pickle looks like -> pickle_lyrics['lyrics'][('song_title', 'artist')]['lyrics']\n",
    "# or - > pickle_lyrics['genre']\n",
    "def load_lyrics():\n",
    "    lyrics_list = []\n",
    "    genres_map = {}\n",
    "    for i,l_path in enumerate(LYRIC_PATHS):\n",
    "        if not os.path.exists(PICKLE_ROOT+l_path):\n",
    "            print('problem occured looking for %s' %(PICKLE_ROOT+l_path))\n",
    "            sys.exit()\n",
    "        print('loading %s%s%s' %(os.getcwd(),PICKLE_ROOT,l_path))\n",
    "        loaded_lyrics = pickle.load(open(PICKLE_ROOT+l_path, \"rb\" ))\n",
    "        genres_map[loaded_lyrics['genre']] = i\n",
    "        lyrics_list.append(loaded_lyrics)\n",
    "        print('number of songs: %d' %(len(loaded_lyrics['lyrics'])))\n",
    "    return lyrics_list, genres_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_and_punct(article):\n",
    "    final_article = []\n",
    "    word_tokens = tokenizer.tokenize(article)\n",
    "    filtered_article = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_article = [x.lower() for x in filtered_article]\n",
    "    filtered_song = ' '.join(filtered_article)\n",
    "    return filtered_song, filtered_article\n",
    "\n",
    "def remove_similar_word(word_list,word_count):\n",
    "    for word in word_list:\n",
    "        keep = True\n",
    "        for key,count in word_count[word].items():\n",
    "            if count < 100:\n",
    "                keep = false\n",
    "        \n",
    "def clean_genre(data,word_count):\n",
    "    song_list = []\n",
    "    unique_words_list = []\n",
    "    count = 0\n",
    "    max_length_song = 0\n",
    "    for key, song_info in data['lyrics'].items():\n",
    "        title, artist = key\n",
    "        inner_title = song_info['title']\n",
    "        if count%1000==0:\n",
    "            print('iter - %d: song - %s' %(count, inner_title))\n",
    "            \n",
    "        inner_artist = song_info['artist']\n",
    "        song_lyrics = song_info['lyrics']\n",
    "        song_lyrics_norm, song_lyrics_split = remove_stop_and_punct(song_lyrics)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if title == inner_title and artist == inner_artist:\n",
    "            if len(song_lyrics_split) <= MAX_SONG_LENGTH:\n",
    "\n",
    "                if len(song_lyrics_split) > max_length_song:\n",
    "                    max_length_song = len(song_lyrics_split)\n",
    "                song_list.append(song_lyrics_norm)\n",
    "                unique_words_list = list(set(unique_words_list + song_lyrics_split))\n",
    "            count+=1\n",
    "        \n",
    "        if count >= SONG_PER_GENRE:\n",
    "            print('hit max songs: %d' %(SONG_PER_GENRE))\n",
    "            print('songs left out: %d' %(len(data['lyrics'])-SONG_PER_GENRE))\n",
    "            print('longest song length: %d' %(max_length_song))\n",
    "            return song_list, unique_words_list, max_length_song\n",
    "       \n",
    "    return song_list, unique_words_list, max_length_song\n",
    "\n",
    "def clean_data(p_lyrics,genre_index,word_count):\n",
    "    lyrics = []\n",
    "    lyrics_labels = []\n",
    "    unique_words_set = []\n",
    "    longest_song = 0\n",
    "    for data in p_lyrics:\n",
    "        genre = data['genre']\n",
    "        print('cleaning: %s' %(genre))\n",
    "        song_list, unique_words, g_longest_song = clean_genre(data,word_count)\n",
    "        unique_words_set = list(set(unique_words_set+unique_words))\n",
    "        song_labels = [genre_index[genre]]*len(song_list)\n",
    "        if longest_song < g_longest_song:\n",
    "            longest_song = g_longest_song\n",
    "        lyrics = lyrics + song_list\n",
    "        lyrics_labels = lyrics_labels + song_labels\n",
    "    return [lyrics, lyrics_labels, unique_words_set, longest_song, genre_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_data(filepath,filename, list_data):\n",
    "    data = {}\n",
    "    print('keys match data: %s' %(len(list_data)==len(DATA_KEYS)))\n",
    "    for key,val in zip(DATA_KEYS,list_data):\n",
    "        data[key] = val\n",
    "    pickle.dump( data, open(filepath+filename, \"wb\" ) )\n",
    "    print('saved data to: %s%s' %(filepath,filename))\n",
    "    \n",
    "def verify_data(filepath,filename, list_data):\n",
    "    loaded_data = pickle.load( open(filepath + filename , \"rb\" ) )\n",
    "    print('keys match loaded data: %s' %(len(loaded_data)==len(list_data)))\n",
    "    for key,val in zip(DATA_KEYS,list_data):\n",
    "        try:\n",
    "            data_check = (len(loaded_data[key])==len(val))\n",
    "        except:\n",
    "            data_check = (loaded_data[key]==val)\n",
    "        if data_check == False:\n",
    "            print('ERROR: Data saved does not match at:')\n",
    "            print(key)\n",
    "            print('please rerun and check paths')\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_per_genre(p_lyrics):\n",
    "    word_count = {}\n",
    "    for data in p_lyrics:\n",
    "        genre = data['genre']\n",
    "        for key, song_info in data['lyrics'].items():\n",
    "            song_lyrics = song_info['lyrics']\n",
    "            song_lyrics_norm, song_lyrics_split = remove_stop_and_punct(song_lyrics)\n",
    "            song_word_count = Counter(song_lyrics_split)\n",
    "            for word, count in song_word_count.items():\n",
    "                if word in word_count:\n",
    "                    if genre in word_count[word]:\n",
    "                        word_count[word][genre]+=count\n",
    "                    else:\n",
    "                        word_count[word][genre] = count\n",
    "                else:\n",
    "                    word_count[word] = {genre: count}\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickles\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring_2019_senior/NLP/project/tag_my_lyrics/preprocessing../data/lyrics/Christian.pickle\n",
      "number of songs: 6895\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring_2019_senior/NLP/project/tag_my_lyrics/preprocessing../data/lyrics/Pop.pickle\n",
      "number of songs: 5818\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring_2019_senior/NLP/project/tag_my_lyrics/preprocessing../data/lyrics/Rock.pickle\n",
      "number of songs: 5596\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring_2019_senior/NLP/project/tag_my_lyrics/preprocessing../data/lyrics/Country.pickle\n",
      "number of songs: 5368\n",
      "loading /Users/Joe/Applications/OneDrive/School/Spring_2019_senior/NLP/project/tag_my_lyrics/preprocessing../data/lyrics/Rap.pickle\n",
      "number of songs: 4747\n",
      "genres dict\n",
      "{'Christian': 0, 'Pop': 1, 'Rock': 2, 'Country': 3, 'Rap': 4}\n",
      "finished loading pickles\n",
      "counting words\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-09a8abc7f426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-09a8abc7f426>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'counting words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_words_per_genre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'love'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-67be1a7b8185>\u001b[0m in \u001b[0;36mcount_words_per_genre\u001b[0;34m(p_lyrics)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msong_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msong_lyrics_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_lyrics_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stop_and_punct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msong_word_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_lyrics_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msong_word_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "def main(argv):\n",
    "    pickle_lyrics = []\n",
    "    genre_index = {}\n",
    "    word_count = {}\n",
    "    print('loading pickles')\n",
    "    pickle_lyrics, genre_index = load_lyrics()\n",
    "    print('genres dict')\n",
    "    print(genre_index)\n",
    "    print('finished loading pickles')\n",
    "    \n",
    "    print('counting words')\n",
    "    word_count = count_words_per_genre(pickle_lyrics)\n",
    "    print(word_count['love'])\n",
    "    sys.exit()\n",
    "    \n",
    "    \n",
    "    print('cleaning data')\n",
    "    new_data = clean_data(pickle_lyrics,genre_index,word_count)\n",
    "    lyrics = new_data[0]\n",
    "    lyrics_labels = new_data[1]\n",
    "    unique_words_set = new_data[2]\n",
    "    longest_song = new_data[3]\n",
    "    print('\\n')\n",
    "    print('number of songs: %d' %(len(lyrics)))\n",
    "    print('number of lyrics: %d' %(len(lyrics_labels)))\n",
    "    print('number of unique words: %d' %(len(unique_words_set)))\n",
    "    print('number of genres: %d' %(len(genre_index)))\n",
    "    print('longest song : %d' %(longest_song))\n",
    "    print('finished cleaning data')\n",
    "    \n",
    "    if SAVE:\n",
    "        \n",
    "        save_prepared_data(PICKLE_ROOT,OUT_PICKLE,new_data)\n",
    "        print('verifying data stored')\n",
    "        verified = verify_data(PICKLE_ROOT,OUT_PICKLE,new_data)\n",
    "        print('All data verified : %s' %(verified))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
